{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Human Activity Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors:  \n",
    "Arin Rahim  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports \n",
    "from utility_functions import*\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from processes.apply_window import apply_window\n",
    "from models.gradient_model import gradient_model\n",
    "from models.randomforest_model import random_forest_model\n",
    "from processes.one_df import one_df\n",
    "from processes.all_data import all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_501 = one_df('501')\n",
    "df_all_data = all_data()\n",
    "\n",
    "# copies \n",
    "sensor_501_df_copy = df_501.copy()\n",
    "all_sensors_df_copy = df_all_data.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Develop a model that can accurately predict the activity based on features. If you use multiple models, report the accuracy (or other relevant score) for all models and motivate which model works best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dropping timestamp column from the datasets \n",
    "sensor_501_df = df_501.drop(['timestamp'], axis=1)\n",
    "all_sensors_df = df_all_data.drop(['timestamp'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient booster and Random forest model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and split the data into traning and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the X and y for all sensors\n",
    "X_all_sensors = all_sensors_df.drop(['label'], axis = 1) # features\n",
    "y_all_sensors = all_sensors_df['label'] # labels\n",
    "\n",
    "# Split the data into training and test sets for all sensor\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all_sensors, y_all_sensors, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the models using the training data from all sensors\n",
    "gb_model_all = gradient_model(X_train_all, y_train_all)\n",
    "rf_model_all = random_forest_model(X_train_all, y_train_all)\n",
    "\n",
    "# Test the models with the test data from all the sensors\n",
    "gb_prediction_all = gb_model_all.predict(X_test_all)\n",
    "rf_prediction_all = rf_model_all.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Futher evaluation using classification report for all the sensors\n",
    "gb_report_all = classification_report(y_test_all, gb_prediction_all)\n",
    "print(\"Gradient Boosting Report for all sensors:\\n\", gb_report_all)\n",
    "\n",
    "rb_report_all = classification_report(y_test_all, rf_prediction_all)\n",
    "print(\"Random Forest Report for all sensors:\\n\", rb_report_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the histogram for the 'label' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "all_sensors_df['label'].hist(bins=len(all_sensors_df['label'].unique()), rwidth=0.8)\n",
    "plt.title('Frequency of Labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Feature engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the minimal set of features that can predict each activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the heat map to show the correlation between the features\n",
    "correlation_matrix_all_data = all_sensors_df.corr()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix_all_data, annot=True, fmt=\".2f\", cmap='coolwarm', center=0, square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.5})\n",
    "plt.title(\"Heat map of the correlation matrix for all sensors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection 1: back_x, back_z, thigh_x, thigh_z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection 1: back_x, back_z, thigh_x, thigh_z for all sensor data \n",
    "X_all_sensors_fs1 = all_sensors_df.drop(['label', 'back_y', 'thigh_y'], axis = 1) # features\n",
    "y_all_sensors_fs1 = all_sensors_df['label'] # labels\n",
    "\n",
    "# Split the dataset into training and testing sets for feature selection 1\n",
    "X_train_fs1, X_test_fs1, y_train_fs1, y_test_fs1 = train_test_split(X_all_sensors_fs1, y_all_sensors_fs1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with the training data for feature selection 1\n",
    "rb_model_fs1 = random_forest_model(X_train_fs1, y_train_fs1)\n",
    "\n",
    "# Test the model with the test data for feature selection 1\n",
    "rb_prediction_fs1 = rb_model_fs1.predict(X_test_fs1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute the model using the classification report for feature selection 1\n",
    "rb_report_fs1 = classification_report(y_test_fs1, rb_prediction_fs1)\n",
    "\n",
    "print(\"Classification Report for Feature Selection 1:\")\n",
    "print(rb_report_fs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection 2: back_x, back_z, thigh_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection 2: back_x, back_z, thigh_x for all sensor data \n",
    "X_all_sensors_fs2 = all_sensors_df.drop(['label', 'back_y', 'thigh_y', 'thigh_z'], axis = 1) # features\n",
    "y_all_sensors_fs2 = all_sensors_df['label'] # labels\n",
    "\n",
    "# Split the dataset into training and testing sets for feature selection 2\n",
    "X_train_fs2, X_test_fs2, y_train_fs2, y_test_fs2 = train_test_split(X_all_sensors_fs2, y_all_sensors_fs2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with the training data for feature selection 2\n",
    "rb_model_fs2 = random_forest_model(X_train_fs2, y_train_fs2)\n",
    "\n",
    "# Test the model with the test data for feature selection 2\n",
    "rb_prediction_fs2 = rb_model_fs2.predict(X_test_fs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute the model using the classification report for feature selection 2\n",
    "rb_report_fs2 = classification_report(y_test_fs2, rb_prediction_fs2)\n",
    "\n",
    "print(\"Classification Report for Feature Selection 2:\")\n",
    "print(rb_report_fs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection 3: back_x and back_z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection 3: back_x, back_z for all sensor data \n",
    "X_all_sensors_fs3 = all_sensors_df.drop(['label', 'back_y', 'thigh_y', 'thigh_z', 'thigh_x'], axis = 1) # features\n",
    "y_all_sensors_fs3 = all_sensors_df['label'] # labels\n",
    "\n",
    "# Split the dataset into training and testing sets for feature selection 3\n",
    "X_train_fs3, X_test_fs3, y_train_fs3, y_test_fs3 = train_test_split(X_all_sensors_fs3, y_all_sensors_fs3, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with the training data for feature selection 3\n",
    "rb_model_fs3 = random_forest_model(X_train_fs3, y_train_fs3)\n",
    "\n",
    "# Test the model with the test data for feature selection 3\n",
    "rb_prediction_fs3 = rb_model_fs3.predict(X_test_fs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute the model using the classification report for feature selection 3\n",
    "rb_report_fs3 = classification_report(y_test_fs3, rb_prediction_fs3)\n",
    "\n",
    "print(\"Classification Report for Feature Selection 2:\")\n",
    "print(rb_report_fs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection 4: back_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection 4: back_x for all sensor data \n",
    "X_all_sensors_fs4 = all_sensors_df.drop(['label', 'back_y', 'thigh_y', 'thigh_z', 'thigh_x', 'back_z'], axis = 1) # features\n",
    "y_all_sensors_fs4 = all_sensors_df['label'] # labels\n",
    "\n",
    "# Split the dataset into training and testing sets for feature selection 4\n",
    "X_train_fs4, X_test_fs4, y_train_fs4, y_test_fs4 = train_test_split(X_all_sensors_fs4, y_all_sensors_fs4, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with the training data for feature selection 4\n",
    "rb_model_fs4 = random_forest_model(X_train_fs4, y_train_fs4)\n",
    "\n",
    "# Test the model with the test data for feature selection 4\n",
    "rb_prediction_fs4 = rb_model_fs4.predict(X_test_fs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute the model using the classification report for feature selection 4\n",
    "rb_report_fs4 = classification_report(y_test_fs4, rb_prediction_fs4)\n",
    "\n",
    "print(\"Classification Report for Feature Selection 4:\")\n",
    "print(rb_report_fs4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection 5: back_x and thigh_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection 5: back_x and thigh_x for all sensor data \n",
    "X_all_sensors_fs5 = all_sensors_df.drop(['label', 'back_y', 'thigh_y', 'thigh_z', 'back_z'], axis = 1) # features\n",
    "y_all_sensors_fs5 = all_sensors_df['label'] # labels\n",
    "\n",
    "# Split the dataset into training and testing sets for feature selection 4\n",
    "X_train_fs5, X_test_fs5, y_train_fs5, y_test_fs5 = train_test_split(X_all_sensors_fs5, y_all_sensors_fs5, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with the training data for feature selection 4\n",
    "rb_model_fs5 = random_forest_model(X_train_fs5, y_train_fs5)\n",
    "\n",
    "# Test the model with the test data for feature selection 4\n",
    "rb_prediction_fs5 = rb_model_fs5.predict(X_test_fs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Feature Selection 5: back_x & thigh_x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.88      0.87    215508\n",
      "           3       0.09      0.04      0.05     13433\n",
      "           4       0.02      0.01      0.01       933\n",
      "           5       0.00      0.00      0.00       995\n",
      "           6       0.71      0.76      0.73     83785\n",
      "           7       0.98      0.99      0.98     96519\n",
      "           8       1.00      1.00      1.00     40747\n",
      "\n",
      "    accuracy                           0.86    451920\n",
      "   macro avg       0.52      0.52      0.52    451920\n",
      "weighted avg       0.85      0.86      0.85    451920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evalute the model using the classification report for feature selection 5\n",
    "rb_report_fs5 = classification_report(y_test_fs5, rb_prediction_fs5)\n",
    "\n",
    "print(\"Classification Report for Feature Selection 5: back_x & thigh_x:\")\n",
    "print(rb_report_fs5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection 6: back_z and thigh_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection 6: back_z and thigh_x for all sensor data \n",
    "X_all_sensors_fs6 = all_sensors_df.drop(['label', 'back_y', 'thigh_y', 'thigh_z', 'back_x'], axis = 1) # features\n",
    "y_all_sensors_fs6 = all_sensors_df['label'] # labels\n",
    "\n",
    "# Split the dataset into training and testing sets for feature selection 6\n",
    "X_train_fs6, X_test_fs6, y_train_fs6, y_test_fs6 = train_test_split(X_all_sensors_fs6, y_all_sensors_fs6, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with the training data for feature selection 6\n",
    "rb_model_fs6 = random_forest_model(X_train_fs6, y_train_fs6)\n",
    "\n",
    "# Test the model with the test data for feature selection 6\n",
    "rb_prediction_fs6 = rb_model_fs6.predict(X_test_fs6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Feature Selection 6: back_z & thigh_x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.87      0.85    215508\n",
      "           3       0.10      0.05      0.06     13433\n",
      "           4       0.02      0.01      0.01       933\n",
      "           5       0.00      0.00      0.00       995\n",
      "           6       0.68      0.69      0.69     83785\n",
      "           7       0.97      0.98      0.98     96519\n",
      "           8       0.99      0.99      0.99     40747\n",
      "\n",
      "    accuracy                           0.84    451920\n",
      "   macro avg       0.51      0.51      0.51    451920\n",
      "weighted avg       0.83      0.84      0.83    451920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evalute the model using the classification report for feature selection 5\n",
    "rb_report_fs6 = classification_report(y_test_fs6, rb_prediction_fs6)\n",
    "\n",
    "print(\"Classification Report for Feature Selection 6: back_z & thigh_x:\")\n",
    "print(rb_report_fs6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Report activity seperation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report which features can seperate the different activities for the smartphone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Define the number of features and create a figure with subplots\n",
    "features = ['back_x', 'back_y', 'back_z', 'thigh_x', 'thigh_y', 'thigh_z']\n",
    "n_features = len(features)\n",
    "fig, axes = plt.subplots(n_features, 1, figsize=(15, 5 * n_features))\n",
    "\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    \n",
    "    sns.violinplot(x='label', y=feature, data=all_sensors_df, ax=axes[i])\n",
    "    axes[i].set_title(f'Violin Plot of {feature} by Activity Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sensors_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first task, two modeles were created, trained and tested with the dataset given. The first model created was a Gradient booster model, and the second was a Random forest model. Both models showed a good performance in terms of accuracy but the model I choose to continue with was the Random forest model beacuse of its slightly higher accuracy compared to the Gradient booster model. The models also had different values between the precision and recall of the classes, where the Random forest model had higher precision and recall precantage for the classes 3, 4, and 5 eventhough the frequency of those classes were low. \n",
    "\n",
    "Relevant scores such as accuracy, precision, recall and F1-score for the models can be found below: \n",
    "\n",
    "Gradient Boosting Report for all sensors:\n",
    "               \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           1       0.91      0.94      0.92    215508\n",
    "           3       0.43      0.00      0.00     13433\n",
    "           4       0.61      0.01      0.02       933\n",
    "           5       0.08      0.00      0.00       995\n",
    "           6       0.80      0.87      0.83     83785\n",
    "           7       1.00      1.00      1.00     96519\n",
    "           8       1.00      1.00      1.00     40747\n",
    "\n",
    "    accuracy                           0.91    451920\n",
    "   \n",
    "\n",
    "Random Forest Report for all sensors:\n",
    "               \n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           1       0.92      0.97      0.94    215508\n",
    "           3       0.68      0.07      0.13     13433\n",
    "           4       0.84      0.10      0.18       933\n",
    "           5       0.87      0.06      0.10       995\n",
    "           6       0.89      0.90      0.90     83785\n",
    "           7       1.00      1.00      1.00     96519\n",
    "           8       1.00      1.00      1.00     40747\n",
    "    \n",
    "    accuracy                           0.94    451920\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the data, a heat map (plots folder) was used to identify the correlation between the features and the labels. The features back_y and thigh_y showed low correlation, meaning that an increase and decrese of those features had small effects on the class predicition. Initally, feature selection started by removing those features, and a backward elimation was used. Multiple Random forest models with different amount of features were trained, and the accuracy of the models decreased as the number of features decreased. However, two models were trained with only two features, and thoes models showed high accuracy but lower than the models with four and three of the features. This indicates that the minimal set of features needed for prediction is 2 but should be picked with thigh_x and either back_x or back_z. \n",
    "\n",
    "Relevants scores such as precision, accuracy, recall and F1 can be found below. \n",
    "\n",
    "Classification Report for Feature Selection 5: back_x & thigh_x:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.87      0.88      0.87    215508\n",
    "           3       0.09      0.04      0.05     13433\n",
    "           4       0.02      0.01      0.01       933\n",
    "           5       0.00      0.00      0.00       995\n",
    "           6       0.71      0.76      0.73     83785\n",
    "           7       0.98      0.99      0.98     96519\n",
    "           8       1.00      1.00      1.00     40747\n",
    "\n",
    "    accuracy                           0.86    451920\n",
    "\n",
    "\n",
    "\n",
    "Classification Report for Feature Selection 6: back_z & thigh_x:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.84      0.87      0.85    215508\n",
    "           3       0.10      0.05      0.06     13433\n",
    "           4       0.02      0.01      0.01       933\n",
    "           5       0.00      0.00      0.00       995\n",
    "           6       0.68      0.69      0.69     83785\n",
    "           7       0.97      0.98      0.98     96519\n",
    "           8       0.99      0.99      0.99     40747\n",
    "\n",
    "    accuracy                           0.84    451920"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify which features that can seperate the different activities, a violin plot was used to visualize the distribution of each activityâ€™s data points (plots folder). Analyze of each plot is as follows:\n",
    "\n",
    "back_x: The back_x features shows a spread variation for activity 6, indicating a wide range of motion but for the activites 1, 3, and 4, the spread of the variation indicates less motion. \n",
    "\n",
    "back_y: The variation for activites 5, 6, 7, and 8 is significant, which means that these activites involve motions with the back. However for activities 1, 3, and 4 shows low variability, indicating less movement of this axis during thoes acitivites. \n",
    "\n",
    "back_z: The activities 6 and 8 shows high variablity, indiciating that thoes activites effect the back sensors in the z-axis. \n",
    "\n",
    "thigh_x: In this axis, the activity 6 stands out with high variability. Conversly, activities 1, 3, and 4 shows tighter distrubutions, indicating a more controlled thigh movement. \n",
    "\n",
    "thigh_y: All the activities shows a high variability, which indicates that every activity effect the thigh sensors y-axis.\n",
    "\n",
    "thigh_z: For activities 7 and 8, the sensor show high variabiliy, suggestion that those acitivites effect the thigh sensors z-axis. \n",
    "\n",
    "In conclusion, the features back_x, back_z, thigh_x, and thigh_z are the featues that can seperate the activities most. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
